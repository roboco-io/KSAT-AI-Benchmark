#!/usr/bin/env python3
"""
í‰ê°€ ê²°ê³¼ ìš”ì•½ ë„êµ¬

results/ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  í‰ê°€ ê²°ê³¼ë¥¼ ì½ì–´ì„œ ìš”ì•½ í…Œì´ë¸”ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
"""

import yaml
from pathlib import Path
from typing import Dict, List, Any
from collections import defaultdict


def load_results() -> Dict[str, List[Dict]]:
    """ëª¨ë“  í‰ê°€ ê²°ê³¼ ë¡œë“œ
    
    Returns:
        {exam_id: [result1, result2, ...]} ë”•ì…”ë„ˆë¦¬
    """
    results_dir = Path("results")
    if not results_dir.exists():
        print("âŒ results/ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {}
    
    results = defaultdict(list)
    
    for exam_dir in results_dir.iterdir():
        if not exam_dir.is_dir():
            continue
        
        exam_id = exam_dir.name
        
        for result_file in exam_dir.glob("*.yaml"):
            with open(result_file, 'r', encoding='utf-8') as f:
                result_data = yaml.safe_load(f)
                results[exam_id].append(result_data)
    
    return dict(results)


def print_summary(results: Dict[str, List[Dict]]):
    """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    
    print("\n" + "="*100)
    print("ğŸ“Š KSAT AI Benchmark - í‰ê°€ ê²°ê³¼ ìš”ì•½")
    print("="*100)
    
    for exam_id, exam_results in results.items():
        if not exam_results:
            continue
        
        # ì²« ë²ˆì§¸ ê²°ê³¼ì—ì„œ ì‹œí—˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        first_result = exam_results[0]
        exam_title = first_result.get('exam_title', exam_id)
        subject = first_result.get('subject', 'unknown')
        
        print(f"\nğŸ“š {exam_title}")
        print(f"   ê³¼ëª©: {subject.upper()}")
        print(f"   í‰ê°€ ëª¨ë¸: {len(exam_results)}ê°œ")
        print()
        
        # í…Œì´ë¸” í—¤ë”
        print(f"{'ëª¨ë¸':<30} {'ì •ë‹µë¥ ':<15} {'ì ìˆ˜':<15} {'í‰ê°€ ì‹œê°„':<15}")
        print("-" * 80)
        
        # ì •í™•ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_results = sorted(
            exam_results,
            key=lambda x: x['summary']['accuracy'],
            reverse=True
        )
        
        for result in sorted_results:
            model_name = result['model_name']
            summary = result['summary']
            
            accuracy = summary['accuracy']
            correct = summary['correct_answers']
            total = summary['total_questions']
            score = summary['total_score']
            max_score = summary['max_score']
            
            # í‰ê°€ ì‹œê°„ ê³„ì‚°
            total_time = sum(r['time_taken'] for r in result['results'])
            
            print(f"{model_name:<30} {accuracy:>5.1f}% ({correct}/{total}){'':<3} {score:>3}/{max_score:<3}ì {'':<4} {total_time:>6.1f}ì´ˆ")
    
    print("\n" + "="*100)
    
    # ì „ì²´ í†µê³„
    total_exams = len(results)
    total_evaluations = sum(len(r) for r in results.values())
    
    print(f"ğŸ“ˆ ì „ì²´ í†µê³„")
    print(f"   - í‰ê°€ëœ ì‹œí—˜: {total_exams}ê°œ")
    print(f"   - ì´ í‰ê°€ íšŸìˆ˜: {total_evaluations}íšŒ")
    print("="*100 + "\n")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    results = load_results()
    
    if not results:
        print("âš ï¸  í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("   í‰ê°€ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”: make evaluate EXAM=...")
        return
    
    print_summary(results)


if __name__ == "__main__":
    main()

