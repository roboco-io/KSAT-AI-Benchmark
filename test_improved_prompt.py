#!/usr/bin/env python3
"""
ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ - ì²« 3ë¬¸ì œë§Œ
"""

import yaml
import os
from dotenv import load_dotenv
from src.evaluator.models.openai_model import OpenAIModel

# .env ë¡œë“œ
load_dotenv()

# ì‹œí—˜ íŒŒì¼ ë¡œë“œ
with open("exams/parsed/2025-korean-sat.yaml", "r", encoding="utf-8") as f:
    exam_data = yaml.safe_load(f)

# ì²« 3ë¬¸ì œë§Œ ì¶”ì¶œ
questions = exam_data["questions"][:3]
passages_map = {p['passage_id']: p['passage_text'] for p in exam_data.get('passages', [])}

print("=" * 80)
print("ğŸ§ª ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ - GPT-5 (ì²« 3ë¬¸ì œ)")
print("=" * 80)

# GPT-5 ëª¨ë¸ ìƒì„±
api_key = os.getenv("OPENAI_API_KEY")
model = OpenAIModel(api_key=api_key, model_name="gpt-5", max_tokens=4096, temperature=1)

# ê° ë¬¸ì œ í…ŒìŠ¤íŠ¸
for i, question in enumerate(questions, 1):
    q_num = question['question_number']
    q_text = question['question_text']
    choices = question['choices']
    correct_answer = question['correct_answer']

    # passage_idë¡œ ì§€ë¬¸ ì¡°íšŒ
    passage = None
    if question.get('passage_id'):
        passage = passages_map.get(question['passage_id'])

    print(f"\n{'='*80}")
    print(f"ğŸ“ ë¬¸ì œ {q_num}ë²ˆ")
    print(f"{'='*80}")
    print(f"ì§ˆë¬¸: {q_text}")
    print(f"ì •ë‹µ: {correct_answer}ë²ˆ")

    # ëª¨ë¸ë¡œ ë¬¸ì œ í’€ì´
    response = model.solve_question(q_text, choices, passage)

    is_correct = response.answer == correct_answer
    status = "âœ… ì •ë‹µ" if is_correct else f"âŒ ì˜¤ë‹µ (ì„ íƒ: {response.answer}ë²ˆ)"

    print(f"ê²°ê³¼: {status}")
    print(f"ì‹œê°„: {response.time_taken:.2f}ì´ˆ")
    print(f"\n[ì¶”ë¡ ]")
    print(response.reasoning[:500] + "..." if len(response.reasoning) > 500 else response.reasoning)

print(f"\n{'='*80}")
print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
print(f"{'='*80}")
